version: "3"

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:5.4.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-enterprise-kafka:5.4.0
    hostname: kafka
    ports:
      # Exposes 9092 for external connections to the broker
      # Use kafka:29092 for connections internal on the docker network
      # See https://rmoff.net/2018/08/02/kafka-listeners-explained/ for details
      - 9092:9092
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka:29092
      CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT: zookeeper:2181
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: 'true'
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'

  schema-registry:
    image: confluentinc/cp-schema-registry:5.4.0
    ports:
      - 8081:8081
    depends_on:
      - zookeeper
      - kafka
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: zookeeper:2181

  kafka-topics:
    image: confluentinc/cp-kafka:5.2.1
    depends_on:
      - kafka
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                           cub kafka-ready -b kafka:29092 1 20 && \
                           kafka-topics --create --topic card-request --if-not-exists --zookeeper zookeeper:2181 --partitions 2 --replication-factor 1 && \
                           kafka-topics --create --topic card-authorization-response --if-not-exists --zookeeper zookeeper:2181 --partitions 2 --replication-factor 1 && \
                           kafka-topics --create --topic card-success --if-not-exists --zookeeper zookeeper:2181 --partitions 2 --replication-factor 1 && \
                           kafka-topics --create --topic card-declines --if-not-exists --zookeeper zookeeper:2181 --partitions 2 --replication-factor 1 && \
                           kafka-topics --create --topic card-undefined --if-not-exists --zookeeper zookeeper:2181 --partitions 2 --replication-factor 1 && \
                           kafka-topics --create --topic daily-success-aggregates --if-not-exists --zookeeper zookeeper:2181 --partitions 2 --replication-factor 1 && \
                           kafka-topics --create --topic daily-declined-aggregates --if-not-exists --zookeeper zookeeper:2181 --partitions 2 --replication-factor 1 && \
                           sleep infinity'"
    environment:
      # The following settings are listed here only to satisfy the image's requirements.
      # We override the image's `command` anyways, hence this container will not start a broker.
      KAFKA_BROKER_ID: ignored
      KAFKA_ZOOKEEPER_CONNECT: ignored

  kafka-producers:
    image: zip-coding-challenge:latest
    depends_on:
      - kafka
      - kafka-topics
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                           cub kafka-ready -b kafka:29092 1 20 && \
                           java -cp /opt/lib/zip-coding-challenge-assembly-0.1.0-SNAPSHOT.jar \
                           au.com.zip.producer.PaymentGatewayProducer'"

  kafka-consumers:
    image: zip-coding-challenge:latest
    depends_on:
      - kafka
      - kafka-topics
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                               cub kafka-ready -b kafka:29092 1 20 && \
                               java -cp /opt/lib/zip-coding-challenge-assembly-0.1.0-SNAPSHOT.jar \
                               au.com.zip.consumer.AuthorizedTransactionConsumer'"

  kafka-daily-aggregates-stream:
    image: zip-coding-challenge:latest
    depends_on:
      - kafka
      - kafka-topics
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                                 cub kafka-ready -b kafka:29092 1 20 && \
                                 java -cp /opt/lib/zip-coding-challenge-assembly-0.1.0-SNAPSHOT.jar \
                                 au.com.zip.stream.DailyAggregatesStream'"

  kafka-monthly-aggregates-stream:
    image: zip-coding-challenge:latest
    depends_on:
      - kafka
      - kafka-topics
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                                 cub kafka-ready -b kafka:29092 1 20 && \
                                 java -cp /opt/lib/zip-coding-challenge-assembly-0.1.0-SNAPSHOT.jar \
                                 au.com.zip.stream.MonthlyAggregatesStream'"

  mysql:
    image: mysql
    container_name: mysql
    ports:
      - 3306:3306
    environment:
      - MYSQL_ROOT_PASSWORD=password
      - MYSQL_USER=TEST
      - MYSQL_PASSWORD=password
      - MYSQL_DATABASE=TEST

  kafka-connect-01:
    image: confluentinc/cp-kafka-connect:5.4.0
    depends_on:
      - zookeeper
      - kafka
      - mysql
    ports:
      - 8083:8083
    environment:
      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
      CONNECT_BOOTSTRAP_SERVERS: "kafka:29092"
      CONNECT_REST_PORT: 8083
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect-01"
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_PLUGIN_PATH: '/usr/share/java'
    command:
      - /bin/bash
      - -c
      - |
        # MySQL
        cd /usr/share/java/kafka-connect-jdbc/
        curl https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.20/mysql-connector-java-8.0.20.jar --output mysql-connector-java-8.0.20.jar
        # Now launch Kafka Connect
        sleep infinity &
        /etc/confluent/docker/run

  kafdrop:
    image: obsidiandynamics/kafdrop
    restart: "no"
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKERCONNECT: "localhost:9092"
      JVM_OPTS: "-Xms16M -Xmx48M -Xss180K -XX:-TieredCompilation -XX:+UseStringDeduplication -noverify"
#    depends_on:
#      - kafka